{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.master(\"local[1]\").appName(\"dataframe_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-UQS9B0T.ht.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframe_sql</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2846dac1f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe using csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df=spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(r\"C:\\Users\\user\\OneDrive\\Desktop\\Big-data-trendytech\\udemy\\RetailDB+SalesData\\RetailDB SalesData\\Orders\\part-00000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating temporary spark table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Top 15 customers who placed the most number of orders using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=order_df.groupBy(\"customer_id\").count().sort(\"count\",ascending=False).limit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       5897|   16|\n",
      "|      12431|   16|\n",
      "|        569|   16|\n",
      "|       6316|   16|\n",
      "|      12284|   15|\n",
      "|       4320|   15|\n",
      "|       5624|   15|\n",
      "|       5283|   15|\n",
      "|        221|   15|\n",
      "|       5654|   15|\n",
      "|       6248|   14|\n",
      "|       3708|   14|\n",
      "|       1011|   14|\n",
      "|       8652|   14|\n",
      "|       4517|   14|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Top 15 customers who placed the most number of orders using sparksql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1_sql=spark.sql(\"select customer_id,count(order_id) as count from orders group by customer_id order by count desc limit 15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       5897|   16|\n",
      "|      12431|   16|\n",
      "|        569|   16|\n",
      "|       6316|   16|\n",
      "|      12284|   15|\n",
      "|       4320|   15|\n",
      "|       5624|   15|\n",
      "|       5283|   15|\n",
      "|        221|   15|\n",
      "|       5654|   15|\n",
      "|       6248|   14|\n",
      "|       3708|   14|\n",
      "|       1011|   14|\n",
      "|       8652|   14|\n",
      "|       4517|   14|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_1_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Find the number of orders under each order status using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_2=order_df.groupBy(\"order_status\").count().sort(\"count\",ascending=False).limit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|   order_status|count|\n",
      "+---------------+-----+\n",
      "|       COMPLETE|22899|\n",
      "|PENDING_PAYMENT|15030|\n",
      "|     PROCESSING| 8275|\n",
      "|        PENDING| 7610|\n",
      "|         CLOSED| 7556|\n",
      "|        ON_HOLD| 3798|\n",
      "|SUSPECTED_FRAUD| 1558|\n",
      "|       CANCELED| 1428|\n",
      "| PAYMENT_REVIEW|  729|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Find the number of orders under each order status using sparksql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2_sql=spark.sql(\"select order_status,count(order_id) as count from orders group by order_status order by count desc limit 15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|   order_status|count|\n",
      "+---------------+-----+\n",
      "|       COMPLETE|22899|\n",
      "|PENDING_PAYMENT|15030|\n",
      "|     PROCESSING| 8275|\n",
      "|        PENDING| 7610|\n",
      "|         CLOSED| 7556|\n",
      "|        ON_HOLD| 3798|\n",
      "|SUSPECTED_FRAUD| 1558|\n",
      "|       CANCELED| 1428|\n",
      "| PAYMENT_REVIEW|  729|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_2_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Number of active customers(who placed atleast one order) using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_3=order_df.select(\"customer_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12405\n"
     ]
    }
   ],
   "source": [
    "print(result_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Number of active customers(who placed atleast one order) using spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ssql_3=spark.sql(\"select count(distinct(customer_id)) as active_customers from orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|active_customers|\n",
      "+----------------+\n",
      "|           12405|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_ssql_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.customers with most number of closed orders using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_4=order_df.filter(\"order_status='CLOSED'\").groupBy('customer_id').count().sort(\"count\",ascending=False).limit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1833|    6|\n",
      "|       1363|    5|\n",
      "|       1687|    5|\n",
      "|       5493|    5|\n",
      "|       7850|    4|\n",
      "|       3631|    4|\n",
      "|       2236|    4|\n",
      "|       1521|    4|\n",
      "|      10111|    4|\n",
      "|       4573|    4|\n",
      "|       2403|    4|\n",
      "|       2774|    4|\n",
      "|       7948|    4|\n",
      "|       2768|    4|\n",
      "|        437|    4|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.customers with most number of closed orders using spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ssql_4=spark.sql(\"select customer_id,count('order_id') as count from orders where order_status='CLOSED' group by customer_id order by count desc limit 15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1833|    6|\n",
      "|       1363|    5|\n",
      "|       1687|    5|\n",
      "|       5493|    5|\n",
      "|       7850|    4|\n",
      "|       3631|    4|\n",
      "|       2236|    4|\n",
      "|       1521|    4|\n",
      "|      10111|    4|\n",
      "|       4573|    4|\n",
      "|       2403|    4|\n",
      "|       2774|    4|\n",
      "|       7948|    4|\n",
      "|       2768|    4|\n",
      "|        437|    4|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_ssql_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
